{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Lens data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------+\n",
      "|movieId|Title                      |\n",
      "+-------+---------------------------+\n",
      "|1      |Toy Story                  |\n",
      "|2      |Jumanji                    |\n",
      "|3      |Grumpier Old Men           |\n",
      "|4      |Waiting to Exhale          |\n",
      "|5      |Father of the Bride Part II|\n",
      "+-------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "86537 movies\n"
     ]
    }
   ],
   "source": [
    "stripYear = F.udf(lambda title: title[:-7])\n",
    "movies_ddf = (spark.read.csv('../../data/movies.csv', header=True, inferSchema=True)\n",
    "              .drop('genres')\n",
    "              .withColumn('Title', stripYear(F.col('title'))))\n",
    "movies_ddf.show(5, False)\n",
    "print(f\"{movies_ddf.count()} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|1     |1      |4.0   |\n",
      "|1     |110    |4.0   |\n",
      "|1     |158    |4.0   |\n",
      "|1     |260    |4.5   |\n",
      "|1     |356    |5.0   |\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "33832162 ratings\n"
     ]
    }
   ],
   "source": [
    "ratings_ddf = (spark.read.csv('../../data/ratings.csv', header=True, inferSchema=True)\n",
    "                .drop('timestamp'))\n",
    "ratings_ddf.show(5, False)\n",
    "print(f\"{ratings_ddf.count()} ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------------+\n",
      "|movieId|Rating            |Title                    |\n",
      "+-------+------------------+-------------------------+\n",
      "|1959   |3.633800573431029 |Out of Africa            |\n",
      "|1591   |2.6484306887532694|Spawn                    |\n",
      "|1580   |3.595333426758223 |Men in Black (a.k.a. MIB)|\n",
      "|1645   |3.56697669143084  |The Devil's Advocate     |\n",
      "|44022  |3.2430483271375463|Ice Age 2: The Meltdown  |\n",
      "+-------+------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lens_ddf = (ratings_ddf\n",
    "  .groupby('movieId')\n",
    "  .avg('rating')\n",
    "  .select(F.col('movieId'), F.col('avg(rating)').alias('Rating'))\n",
    "  .join(movies_ddf, 'movieId'))\n",
    "lens_ddf.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+------+\n",
      "|Id |Title                   |Rating|\n",
      "+---+------------------------+------+\n",
      "|1  |The Shawshank Redemption|9.2   |\n",
      "|2  |The Godfather           |9.2   |\n",
      "|3  |The Godfather: Part II  |9     |\n",
      "|4  |Pulp Fiction            |8.9   |\n",
      "|5  |Schindler's List        |8.9   |\n",
      "+---+------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_df = (spark.read.csv('../../data/imdb_sample.csv', sep=';', header='true')\n",
    "           .select('Id', 'Title', F.col('ImdbScore').alias('Rating')))\n",
    "IMDB_df.show(5, False)\n",
    "IMDB_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When joining on (exact) Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = IMDB_df.join(lens_ddf, 'Title')\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Linkage (Fuzzy Matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare join column by doing multiple transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover, Tokenizer, NGram, HashingTF, MinHashLSH, RegexTokenizer, SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinHashLSHModel: uid=MinHashLSH_651afdbe70c8, numHashTables=3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlTrans = SQLTransformer(statement=\"SELECT *, lower(Title) lower FROM __THIS__\")\n",
    "df1 = sqlTrans.transform(lens_ddf)\n",
    "tokenizer = Tokenizer(inputCol=\"lower\", outputCol=\"token\")\n",
    "df2 = tokenizer.transform(df1)\n",
    "remover = StopWordsRemover(inputCol=\"token\", outputCol=\"stop\")\n",
    "df3 = remover.transform(df2)\n",
    "sqlTrans = SQLTransformer(statement=\"SELECT *, concat_ws(' ', stop) concat FROM __THIS__\")\n",
    "df4 = sqlTrans.transform(df3)\n",
    "rtokenizer = RegexTokenizer(pattern=\"\", inputCol=\"concat\", outputCol=\"char\", minTokenLength=1)\n",
    "df5 = rtokenizer.transform(df4)\n",
    "ngram = NGram(n=2, inputCol=\"char\", outputCol=\"ngram\")\n",
    "df6 = ngram.transform(df5)\n",
    "hashtf = HashingTF(inputCol=\"ngram\", outputCol=\"vector\")\n",
    "df7 = hashtf.transform(df6)\n",
    "minhash = MinHashLSH(inputCol=\"vector\", outputCol=\"lsh\", numHashTables=3)\n",
    "model = minhash.fit(df7)\n",
    "model.setInputCol(\"vector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lsh'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.transform(df7).show(10,False)\n",
    "#df6.count()\n",
    "model.getOutputCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example transformation (82905 movies left):\n",
      "+-------+-------------+------+------------------+--------------------+--------------------+--------------------+\n",
      "|movieId|        Title|concat|              char|               ngram|              vector|                 lsh|\n",
      "+-------+-------------+------+------------------+--------------------+--------------------+--------------------+\n",
      "|   1959|Out of Africa|africa|[a, f, r, i, c, a]|[a f, f r, r i, i...|(262144,[5118,318...|[[1.79617336E8], ...|\n",
      "+-------+-------------+------+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover, Tokenizer, NGram, HashingTF, MinHashLSH, RegexTokenizer, SQLTransformer\n",
    "\n",
    "model = Pipeline(stages=[\n",
    "    SQLTransformer(statement=\"SELECT *, lower(Title) lower FROM __THIS__\"),\n",
    "    Tokenizer(inputCol=\"lower\", outputCol=\"token\"),\n",
    "    StopWordsRemover(inputCol=\"token\", outputCol=\"stop\"),\n",
    "    SQLTransformer(statement=\"SELECT *, concat_ws(' ', stop) concat FROM __THIS__\"),\n",
    "    RegexTokenizer(pattern=\"\", inputCol=\"concat\", outputCol=\"char\", minTokenLength=1),\n",
    "    NGram(n=2, inputCol=\"char\", outputCol=\"ngram\"),\n",
    "    HashingTF(inputCol=\"ngram\", outputCol=\"vector\"),\n",
    "    MinHashLSH(inputCol=\"vector\", outputCol=\"lsh\", numHashTables=3)\n",
    "]).fit(lens_ddf)\n",
    "\n",
    "result_lens = model.transform(lens_ddf)\n",
    "result_lens = result_lens.filter(F.size(F.col(\"ngram\")) > 0)\n",
    "print(f\"Example transformation ({result_lens.count()} movies left):\")\n",
    "result_lens.select('movieId', 'Title', 'concat', 'char', 'ngram', 'vector', 'lsh').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinHashLSHModel: uid=MinHashLSH_7d2003f0168a, numHashTables=3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out rows: 1\n",
      "+---+-----+------+----+-----+--------------+\n",
      "| id|Title|concat|char|ngram|        vector|\n",
      "+---+-----+------+----+-----+--------------+\n",
      "| 69|    M|     m| [m]|   []|(262144,[],[])|\n",
      "+---+-----+------+----+-----+--------------+\n",
      "\n",
      "Example transformation (99 movies left):\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|               Title|              concat|                char|               ngram|              vector|                 lsh|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1|The Shawshank Red...|shawshank redemption|[s, h, a, w, s, h...|[s h, h a, a w, w...|(262144,[6924,327...|[[1.95771365E8], ...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use pipeline previous defined\n",
    "result_imdb = model.transform(IMDB_df)\n",
    "filtered = result_imdb.filter(F.size(F.col(\"ngram\")) < 1)\n",
    "print(f\"Filtered out rows: {filtered.count()}\")\n",
    "filtered.select('id', 'Title', 'concat', 'char', 'ngram', 'vector').show()\n",
    "result_imdb = result_imdb.filter(F.size(F.col(\"ngram\")) > 0)\n",
    "print(f\"Example transformation ({result_imdb.count()} movies left):\")\n",
    "result_imdb.select('id', 'Title', 'concat', 'char', 'ngram', 'vector', 'lsh').show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join based on Jaccard Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434 matches\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|               Title|               Title|         jaccardDist|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  1|The Shawshank Red...|Shawshank Redempt...| 0.05555555555555558|\n",
      "| 10|          Fight Club|   Female Fight Club|              0.4375|\n",
      "| 10|          Fight Club|          Fight Club|                 0.0|\n",
      "| 10|          Fight Club|   Zombie Fight Club|              0.4375|\n",
      "|100| Inglorious Basterds|Inglourious Basterds| 0.10526315789473684|\n",
      "|100| Inglorious Basterds|The Real Inglorio...|                0.36|\n",
      "| 11|The Lord of the R...|Lord of the Rings...|0.045454545454545414|\n",
      "| 12|        Forrest Gump|        Forrest Gump|                 0.0|\n",
      "| 13|          Goodfellas|          Goodfellas|                 0.0|\n",
      "| 14|One Flew Over the...|One Flew Over the...| 0.04761904761904767|\n",
      "| 15|Star Wars Episode...|Star Wars: Episod...|  0.1578947368421053|\n",
      "| 16|           Inception|       Misconception| 0.41666666666666663|\n",
      "| 16|           Inception|           Deception|                 0.4|\n",
      "| 16|           Inception|           Inception|                 0.0|\n",
      "| 16|           Inception|          Perception|  0.4545454545454546|\n",
      "| 16|           Inception|           Deception|                 0.4|\n",
      "| 16|           Inception|          Conception|  0.2222222222222222|\n",
      "| 16|           Inception|          Deceptions|  0.4545454545454546|\n",
      "| 16|           Inception|           Deception|                 0.4|\n",
      "| 16|           Inception|           Deception|                 0.4|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.stages[-1].approxSimilarityJoin(result_imdb, result_lens, 0.5, \"jaccardDist\")\n",
    "print(f\"{result.count()} matches\")\n",
    "(result\n",
    " .select('datasetA.id', 'datasetA.Title', 'datasetB.Title', 'jaccardDist')\n",
    " .sort(F.col('datasetA.id'))\n",
    " .show(20, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datasetA: struct (nullable = false)\n",
      " |    |-- Id: string (nullable = true)\n",
      " |    |-- Title: string (nullable = true)\n",
      " |    |-- Rating: string (nullable = true)\n",
      " |    |-- lower: string (nullable = true)\n",
      " |    |-- token: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- stop: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- concat: string (nullable = false)\n",
      " |    |-- char: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- ngram: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- vector: vector (nullable = true)\n",
      " |    |-- lsh: array (nullable = true)\n",
      " |    |    |-- element: vector (containsNull = true)\n",
      " |-- datasetB: struct (nullable = false)\n",
      " |    |-- movieId: integer (nullable = true)\n",
      " |    |-- Rating: double (nullable = true)\n",
      " |    |-- Title: string (nullable = true)\n",
      " |    |-- lower: string (nullable = true)\n",
      " |    |-- token: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- stop: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- concat: string (nullable = false)\n",
      " |    |-- char: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- ngram: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- vector: vector (nullable = true)\n",
      " |    |-- lsh: array (nullable = true)\n",
      " |    |    |-- element: vector (containsNull = true)\n",
      " |-- jaccardDist: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization: Only keep single row with lowest distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 matches\n",
      "+---------------------------------------------+--------------------------------------------------+--------------------+\n",
      "|Title                                        |Title                                             |jaccardDist         |\n",
      "+---------------------------------------------+--------------------------------------------------+--------------------+\n",
      "|The Shawshank Redemption                     |Shawshank Redemption, The                         |0.05555555555555558 |\n",
      "|Fight Club                                   |Fight Club                                        |0.0                 |\n",
      "|Inglorious Basterds                          |Inglourious Basterds                              |0.10526315789473684 |\n",
      "|The Lord of the Rings: Fellowship of the Ring|Lord of the Rings: The Fellowship of the Ring, The|0.045454545454545414|\n",
      "|Forrest Gump                                 |Forrest Gump                                      |0.0                 |\n",
      "|Goodfellas                                   |Goodfellas                                        |0.0                 |\n",
      "|One Flew Over the Cuckoo's Nnest             |One Flew Over the Cuckoo's Nest                   |0.04761904761904767 |\n",
      "|Star Wars Episode V – The Empire Strikes Back|Star Wars: Episode V - The Empire Strikes Back    |0.1578947368421053  |\n",
      "|Inception                                    |Inception                                         |0.0                 |\n",
      "|The Lord of the Rings: The two towers        |Lord of the Rings: The Two Towers, The            |0.04761904761904767 |\n",
      "|The Matrix                                   |Matrix, The                                       |0.16666666666666663 |\n",
      "|Star Wars Episode IV – A New Hope            |Star Wars: Episode IV - A New Hope                |0.21212121212121215 |\n",
      "|The Godfather                                |GodFather                                         |0.0                 |\n",
      "|The Godfather                                |GodFather                                         |0.0                 |\n",
      "|The Godfather                                |Our Godfather                                     |0.0                 |\n",
      "|Seven Samurai                                |Eleven Samurai                                    |0.2142857142857143  |\n",
      "|Psycho                                       |Psycho                                            |0.0                 |\n",
      "|Psycho                                       |Psycho                                            |0.0                 |\n",
      "|Psycho                                       |Psycho                                            |0.0                 |\n",
      "|The Silence of the Lambs                     |Silence of the Lambs, The                         |0.07692307692307687 |\n",
      "+---------------------------------------------+--------------------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "w = Window.partitionBy('datasetA.id')\n",
    "result = (result\n",
    "           .withColumn('minDist', F.min('jaccardDist').over(w))\n",
    "           .where(F.col('jaccardDist') == F.col('minDist'))\n",
    "           .drop('minDist'))\n",
    "print(f\"{result.count()} matches\")\n",
    "(result\n",
    " .select('datasetA.Title', 'datasetB.Title', 'jaccardDist')\n",
    " .sort(F.col('datasetA.id'))\n",
    " .show(20,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Missed IDs: 27, 34, 49, 67, 69, 70, 89, 96\n",
    "* Faulty Matches: 2, 20, 29, 31, 62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------------------+\n",
      "|               Title|               Title|Rating|            Rating|\n",
      "+--------------------+--------------------+------+------------------+\n",
      "|               Alien|               Alien|   8.5| 4.055518882196001|\n",
      "|Star Wars Episode...|Star Wars: Episod...|   8.7| 4.144122313069856|\n",
      "|       The Lion King|       The Lion King|   8.4|  3.14922480620155|\n",
      "|The Lord of the R...|Lord of the Rings...|   8.8| 4.091188818716808|\n",
      "|Once upon a Time ...|    Once Upon a Time|   8.6|3.3636363636363638|\n",
      "+--------------------+--------------------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('datasetA.Title', 'datasetB.Title', 'datasetA.Rating', 'datasetB.Rating').show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
